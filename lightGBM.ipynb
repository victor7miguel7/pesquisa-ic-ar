{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10218a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\victo\\AppData\\Local\\Temp\\ipykernel_11976\\4080736814.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "370b7512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Timezone</th>\n",
       "      <th>Datetime_start</th>\n",
       "      <th>Datetime_end</th>\n",
       "      <th>AQI US</th>\n",
       "      <th>AQI CN</th>\n",
       "      <th>PM2.5 (ug/m3)</th>\n",
       "      <th>PM10 (ug/m3)</th>\n",
       "      <th>PM1 (ug/m3)</th>\n",
       "      <th>CO2 (ppm)</th>\n",
       "      <th>...</th>\n",
       "      <th>slot.3.co</th>\n",
       "      <th>slot.4.co2</th>\n",
       "      <th>slot.4.pm1</th>\n",
       "      <th>slot.4.pm10</th>\n",
       "      <th>slot.4.pm25</th>\n",
       "      <th>slot.4.pc</th>\n",
       "      <th>slot.4.voc</th>\n",
       "      <th>slot.4.hcho</th>\n",
       "      <th>slot.4.o3</th>\n",
       "      <th>slot.4.co</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>orew7oys376</td>\n",
       "      <td>America/Recife UTC-03:00</td>\n",
       "      <td>2024-11-01 00:00:00</td>\n",
       "      <td>2024-11-01 00:00:59</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>401</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>orew7oys376</td>\n",
       "      <td>America/Recife UTC-03:00</td>\n",
       "      <td>2024-11-01 00:01:00</td>\n",
       "      <td>2024-11-01 00:01:59</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>401</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>288</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>orew7oys376</td>\n",
       "      <td>America/Recife UTC-03:00</td>\n",
       "      <td>2024-11-01 00:02:00</td>\n",
       "      <td>2024-11-01 00:02:59</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>401</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>orew7oys376</td>\n",
       "      <td>America/Recife UTC-03:00</td>\n",
       "      <td>2024-11-01 00:03:00</td>\n",
       "      <td>2024-11-01 00:03:59</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>400</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>289</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>orew7oys376</td>\n",
       "      <td>America/Recife UTC-03:00</td>\n",
       "      <td>2024-11-01 00:04:00</td>\n",
       "      <td>2024-11-01 00:04:59</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>401</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>266</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126228</th>\n",
       "      <td>i2tns66k5l5</td>\n",
       "      <td>America/Recife UTC-03:00</td>\n",
       "      <td>2024-11-30 23:55:00</td>\n",
       "      <td>2024-11-30 23:55:59</td>\n",
       "      <td>33</td>\n",
       "      <td>9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>404</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>269</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126229</th>\n",
       "      <td>i2tns66k5l5</td>\n",
       "      <td>America/Recife UTC-03:00</td>\n",
       "      <td>2024-11-30 23:56:00</td>\n",
       "      <td>2024-11-30 23:56:59</td>\n",
       "      <td>39</td>\n",
       "      <td>10</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>403</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>279</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126230</th>\n",
       "      <td>i2tns66k5l5</td>\n",
       "      <td>America/Recife UTC-03:00</td>\n",
       "      <td>2024-11-30 23:57:00</td>\n",
       "      <td>2024-11-30 23:57:59</td>\n",
       "      <td>33</td>\n",
       "      <td>9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>403</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>239</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126231</th>\n",
       "      <td>i2tns66k5l5</td>\n",
       "      <td>America/Recife UTC-03:00</td>\n",
       "      <td>2024-11-30 23:58:00</td>\n",
       "      <td>2024-11-30 23:58:59</td>\n",
       "      <td>33</td>\n",
       "      <td>9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>403</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126232</th>\n",
       "      <td>i2tns66k5l5</td>\n",
       "      <td>America/Recife UTC-03:00</td>\n",
       "      <td>2024-11-30 23:59:00</td>\n",
       "      <td>2024-11-30 23:59:59</td>\n",
       "      <td>33</td>\n",
       "      <td>9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>403</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>289</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126233 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Source                  Timezone       Datetime_start  \\\n",
       "0       orew7oys376  America/Recife UTC-03:00  2024-11-01 00:00:00   \n",
       "1       orew7oys376  America/Recife UTC-03:00  2024-11-01 00:01:00   \n",
       "2       orew7oys376  America/Recife UTC-03:00  2024-11-01 00:02:00   \n",
       "3       orew7oys376  America/Recife UTC-03:00  2024-11-01 00:03:00   \n",
       "4       orew7oys376  America/Recife UTC-03:00  2024-11-01 00:04:00   \n",
       "...             ...                       ...                  ...   \n",
       "126228  i2tns66k5l5  America/Recife UTC-03:00  2024-11-30 23:55:00   \n",
       "126229  i2tns66k5l5  America/Recife UTC-03:00  2024-11-30 23:56:00   \n",
       "126230  i2tns66k5l5  America/Recife UTC-03:00  2024-11-30 23:57:00   \n",
       "126231  i2tns66k5l5  America/Recife UTC-03:00  2024-11-30 23:58:00   \n",
       "126232  i2tns66k5l5  America/Recife UTC-03:00  2024-11-30 23:59:00   \n",
       "\n",
       "               Datetime_end  AQI US  AQI CN  PM2.5 (ug/m3)  PM10 (ug/m3)  \\\n",
       "0       2024-11-01 00:00:59      19       5            3.5           6.5   \n",
       "1       2024-11-01 00:01:59      17       4            3.0           5.5   \n",
       "2       2024-11-01 00:02:59      14       4            2.5           5.0   \n",
       "3       2024-11-01 00:03:59      19       5            3.5           6.5   \n",
       "4       2024-11-01 00:04:59      19       5            3.5           7.0   \n",
       "...                     ...     ...     ...            ...           ...   \n",
       "126228  2024-11-30 23:55:59      33       9            6.0          16.0   \n",
       "126229  2024-11-30 23:56:59      39      10            7.0          16.0   \n",
       "126230  2024-11-30 23:57:59      33       9            6.0          16.0   \n",
       "126231  2024-11-30 23:58:59      33       9            6.0          15.0   \n",
       "126232  2024-11-30 23:59:59      33       9            6.0          14.0   \n",
       "\n",
       "        PM1 (ug/m3)  CO2 (ppm)  ...  slot.3.co  slot.4.co2  slot.4.pm1  \\\n",
       "0               2.0        401  ...        NaN         NaN           2   \n",
       "1               2.0        401  ...        NaN         NaN           2   \n",
       "2               2.0        401  ...        NaN         NaN           2   \n",
       "3               2.0        400  ...        NaN         NaN           2   \n",
       "4               2.0        401  ...        NaN         NaN           2   \n",
       "...             ...        ...  ...        ...         ...         ...   \n",
       "126228          2.0        404  ...        NaN         NaN           2   \n",
       "126229          2.0        403  ...        NaN         NaN           2   \n",
       "126230          2.0        403  ...        NaN         NaN           2   \n",
       "126231          2.0        403  ...        NaN         NaN           2   \n",
       "126232          2.0        403  ...        NaN         NaN           2   \n",
       "\n",
       "        slot.4.pm10  slot.4.pm25  slot.4.pc  slot.4.voc  slot.4.hcho  \\\n",
       "0                 8            4        300         NaN          NaN   \n",
       "1                 8            4        288         NaN          NaN   \n",
       "2                 7            3        286         NaN          NaN   \n",
       "3                 7            4        289         NaN          NaN   \n",
       "4                 6            3        266         NaN          NaN   \n",
       "...             ...          ...        ...         ...          ...   \n",
       "126228           18            7        269         NaN          NaN   \n",
       "126229           13            6        279         NaN          NaN   \n",
       "126230           11            4        239         NaN          NaN   \n",
       "126231           13            5        260         NaN          NaN   \n",
       "126232           14            6        289         NaN          NaN   \n",
       "\n",
       "        slot.4.o3  slot.4.co  \n",
       "0             NaN        NaN  \n",
       "1             NaN        NaN  \n",
       "2             NaN        NaN  \n",
       "3             NaN        NaN  \n",
       "4             NaN        NaN  \n",
       "...           ...        ...  \n",
       "126228        NaN        NaN  \n",
       "126229        NaN        NaN  \n",
       "126230        NaN        NaN  \n",
       "126231        NaN        NaN  \n",
       "126232        NaN        NaN  \n",
       "\n",
       "[126233 rows x 59 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_concatenado = pd.read_csv('df_concatenado.csv')\n",
    "display(df_concatenado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d31efa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar colunas com valores nulos maiores ou igual que 0\n",
    "limite = 0\n",
    "df_filtrado = df_concatenado.loc[:, df_concatenado.isnull().sum() <= limite]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fa03af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\victo\\AppData\\Local\\Temp\\ipykernel_11976\\969740995.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['Datetime_start'] = pd.to_datetime(df_filtrado['Datetime_start'])\n",
      "C:\\Users\\victo\\AppData\\Local\\Temp\\ipykernel_11976\\969740995.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['Year'] = df_filtrado['Datetime_start'].dt.year                # Ano\n",
      "C:\\Users\\victo\\AppData\\Local\\Temp\\ipykernel_11976\\969740995.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['Month'] = df_filtrado['Datetime_start'].dt.month              # Mês\n",
      "C:\\Users\\victo\\AppData\\Local\\Temp\\ipykernel_11976\\969740995.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['Day'] = df_filtrado['Datetime_start'].dt.day                  # Dia\n",
      "C:\\Users\\victo\\AppData\\Local\\Temp\\ipykernel_11976\\969740995.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['Hour'] = df_filtrado['Datetime_start'].dt.hour                # Hora\n",
      "C:\\Users\\victo\\AppData\\Local\\Temp\\ipykernel_11976\\969740995.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['Weekday'] = df_filtrado['Datetime_start'].dt.weekday # Dia da semana(OBS: Para função weekday a semana vai da contagem segunda 0 ate domingo 6)\n",
      "C:\\Users\\victo\\AppData\\Local\\Temp\\ipykernel_11976\\969740995.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['Is_Weekend'] = df_filtrado['Weekday'].isin([5, 6]).astype(int) # Fim de semana\n",
      "C:\\Users\\victo\\AppData\\Local\\Temp\\ipykernel_11976\\969740995.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['Season'] = df_filtrado['Month'].apply(get_season)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Timezone</th>\n",
       "      <th>Datetime_start</th>\n",
       "      <th>Datetime_end</th>\n",
       "      <th>AQI US</th>\n",
       "      <th>AQI CN</th>\n",
       "      <th>PM2.5 (ug/m3)</th>\n",
       "      <th>PM10 (ug/m3)</th>\n",
       "      <th>PM1 (ug/m3)</th>\n",
       "      <th>CO2 (ppm)</th>\n",
       "      <th>...</th>\n",
       "      <th>slot.4.pm10</th>\n",
       "      <th>slot.4.pm25</th>\n",
       "      <th>slot.4.pc</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Is_Weekend</th>\n",
       "      <th>Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>orew7oys376</td>\n",
       "      <td>America/Recife UTC-03:00</td>\n",
       "      <td>2024-11-01 00:00:00</td>\n",
       "      <td>2024-11-01 00:00:59</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>401</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Primavera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>orew7oys376</td>\n",
       "      <td>America/Recife UTC-03:00</td>\n",
       "      <td>2024-11-01 00:01:00</td>\n",
       "      <td>2024-11-01 00:01:59</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>401</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>288</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Primavera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>orew7oys376</td>\n",
       "      <td>America/Recife UTC-03:00</td>\n",
       "      <td>2024-11-01 00:02:00</td>\n",
       "      <td>2024-11-01 00:02:59</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>401</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>286</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Primavera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>orew7oys376</td>\n",
       "      <td>America/Recife UTC-03:00</td>\n",
       "      <td>2024-11-01 00:03:00</td>\n",
       "      <td>2024-11-01 00:03:59</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>400</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>289</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Primavera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>orew7oys376</td>\n",
       "      <td>America/Recife UTC-03:00</td>\n",
       "      <td>2024-11-01 00:04:00</td>\n",
       "      <td>2024-11-01 00:04:59</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>401</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>266</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Primavera</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Source                  Timezone      Datetime_start  \\\n",
       "0  orew7oys376  America/Recife UTC-03:00 2024-11-01 00:00:00   \n",
       "1  orew7oys376  America/Recife UTC-03:00 2024-11-01 00:01:00   \n",
       "2  orew7oys376  America/Recife UTC-03:00 2024-11-01 00:02:00   \n",
       "3  orew7oys376  America/Recife UTC-03:00 2024-11-01 00:03:00   \n",
       "4  orew7oys376  America/Recife UTC-03:00 2024-11-01 00:04:00   \n",
       "\n",
       "          Datetime_end  AQI US  AQI CN  PM2.5 (ug/m3)  PM10 (ug/m3)  \\\n",
       "0  2024-11-01 00:00:59      19       5            3.5           6.5   \n",
       "1  2024-11-01 00:01:59      17       4            3.0           5.5   \n",
       "2  2024-11-01 00:02:59      14       4            2.5           5.0   \n",
       "3  2024-11-01 00:03:59      19       5            3.5           6.5   \n",
       "4  2024-11-01 00:04:59      19       5            3.5           7.0   \n",
       "\n",
       "   PM1 (ug/m3)  CO2 (ppm)  ...  slot.4.pm10  slot.4.pm25  slot.4.pc  Year  \\\n",
       "0          2.0        401  ...            8            4        300  2024   \n",
       "1          2.0        401  ...            8            4        288  2024   \n",
       "2          2.0        401  ...            7            3        286  2024   \n",
       "3          2.0        400  ...            7            4        289  2024   \n",
       "4          2.0        401  ...            6            3        266  2024   \n",
       "\n",
       "   Month  Day  Hour  Weekday  Is_Weekend     Season  \n",
       "0     11    1     0        4           0  Primavera  \n",
       "1     11    1     0        4           0  Primavera  \n",
       "2     11    1     0        4           0  Primavera  \n",
       "3     11    1     0        4           0  Primavera  \n",
       "4     11    1     0        4           0  Primavera  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Converter a coluna 'Datetime_start' para datetime\n",
    "df_filtrado['Datetime_start'] = pd.to_datetime(df_filtrado['Datetime_start'])\n",
    "\n",
    "# Extrair informações temporais de 'Datetime_start'\n",
    "df_filtrado['Year'] = df_filtrado['Datetime_start'].dt.year                # Ano\n",
    "df_filtrado['Month'] = df_filtrado['Datetime_start'].dt.month              # Mês\n",
    "df_filtrado['Day'] = df_filtrado['Datetime_start'].dt.day                  # Dia\n",
    "df_filtrado['Hour'] = df_filtrado['Datetime_start'].dt.hour                # Hora\n",
    "df_filtrado['Weekday'] = df_filtrado['Datetime_start'].dt.weekday # Dia da semana(OBS: Para função weekday a semana vai da contagem segunda 0 ate domingo 6)\n",
    "df_filtrado['Is_Weekend'] = df_filtrado['Weekday'].isin([5, 6]).astype(int) # Fim de semana\n",
    "\n",
    "# Estações do ano (baseado no hemisfério sul)\n",
    "def get_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'Verão'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'Outono'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'Inverno'\n",
    "    else:\n",
    "        return 'Primavera'\n",
    "\n",
    "df_filtrado['Season'] = df_filtrado['Month'].apply(get_season)\n",
    "\n",
    "\n",
    "# Visualizar as primeiras linhas\n",
    "df_filtrado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc33b836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>AQI US</th>\n",
       "      <th>CO2 (ppm)</th>\n",
       "      <th>Temperature (Celsius)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>slot.2.pm1</th>\n",
       "      <th>slot.2.pm10</th>\n",
       "      <th>slot.2.pm25</th>\n",
       "      <th>slot.2.pc</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Is_Weekend</th>\n",
       "      <th>Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>orew7oys376</td>\n",
       "      <td>19</td>\n",
       "      <td>401</td>\n",
       "      <td>26.3</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>234</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Primavera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>orew7oys376</td>\n",
       "      <td>17</td>\n",
       "      <td>401</td>\n",
       "      <td>26.3</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Primavera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>orew7oys376</td>\n",
       "      <td>14</td>\n",
       "      <td>401</td>\n",
       "      <td>26.4</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>207</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Primavera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>orew7oys376</td>\n",
       "      <td>19</td>\n",
       "      <td>400</td>\n",
       "      <td>26.6</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>226</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Primavera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>orew7oys376</td>\n",
       "      <td>19</td>\n",
       "      <td>401</td>\n",
       "      <td>26.6</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>234</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Primavera</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Source  AQI US  CO2 (ppm)  Temperature (Celsius)  Humidity (%)  \\\n",
       "0  orew7oys376      19        401                   26.3            75   \n",
       "1  orew7oys376      17        401                   26.3            75   \n",
       "2  orew7oys376      14        401                   26.4            75   \n",
       "3  orew7oys376      19        400                   26.6            75   \n",
       "4  orew7oys376      19        401                   26.6            75   \n",
       "\n",
       "   slot.2.pm1  slot.2.pm10  slot.2.pm25  slot.2.pc  Year  Month  Day  Hour  \\\n",
       "0           2            5            3        234  2024     11    1     0   \n",
       "1           2            3            2        242  2024     11    1     0   \n",
       "2           2            3            2        207  2024     11    1     0   \n",
       "3           2            6            3        226  2024     11    1     0   \n",
       "4           2            8            4        234  2024     11    1     0   \n",
       "\n",
       "   Weekday  Is_Weekend     Season  \n",
       "0        4           0  Primavera  \n",
       "1        4           0  Primavera  \n",
       "2        4           0  Primavera  \n",
       "3        4           0  Primavera  \n",
       "4        4           0  Primavera  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remover as colunas \n",
    "df_filtrado = df_filtrado.drop(['Datetime_start', 'Datetime_end','Timezone','Temperature (Fahrenheit)', 'AQI CN',\"PM2.5 (ug/m3)\",'PM10 (ug/m3)', 'PM1 (ug/m3)','slot.4.pm1','slot.4.pm10','slot.4.pm25','Particle Count','slot.4.pc','Pressure (pascal)'], axis=1)\n",
    "df_filtrado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1c8700a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 126233 entries, 0 to 126232\n",
      "Data columns (total 16 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   Source                 126233 non-null  int32  \n",
      " 1   AQI US                 126233 non-null  int64  \n",
      " 2   CO2 (ppm)              126233 non-null  int64  \n",
      " 3   Temperature (Celsius)  126233 non-null  float64\n",
      " 4   Humidity (%)           126233 non-null  int64  \n",
      " 5   slot.2.pm1             126233 non-null  int64  \n",
      " 6   slot.2.pm10            126233 non-null  int64  \n",
      " 7   slot.2.pm25            126233 non-null  int64  \n",
      " 8   slot.2.pc              126233 non-null  int64  \n",
      " 9   Year                   126233 non-null  int32  \n",
      " 10  Month                  126233 non-null  int32  \n",
      " 11  Day                    126233 non-null  int32  \n",
      " 12  Hour                   126233 non-null  int32  \n",
      " 13  Weekday                126233 non-null  int32  \n",
      " 14  Is_Weekend             126233 non-null  int32  \n",
      " 15  Season                 126233 non-null  int32  \n",
      "dtypes: float64(1), int32(8), int64(7)\n",
      "memory usage: 11.6 MB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Instanciando o LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Transformando as colunas de categorias em números\n",
    "df_filtrado['Season'] = label_encoder.fit_transform(df_filtrado['Season'])\n",
    "df_filtrado['Source'] = label_encoder.fit_transform(df_filtrado['Source'])\n",
    "\n",
    "df_filtrado.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63c02c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X = df_filtrado.drop('AQI US',axis=1)\n",
    "\n",
    "# Target(alvo)\n",
    "\n",
    "y = df_filtrado['AQI US']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e0e0718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004312 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 924\n",
      "[LightGBM] [Info] Number of data points in the train set: 113609, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 36.368492\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001180 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 921\n",
      "[LightGBM] [Info] Number of data points in the train set: 113609, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 36.670017\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006251 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 911\n",
      "[LightGBM] [Info] Number of data points in the train set: 113609, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 35.904092\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001221 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 909\n",
      "[LightGBM] [Info] Number of data points in the train set: 113610, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 36.283813\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004091 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 856\n",
      "[LightGBM] [Info] Number of data points in the train set: 113610, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 35.306109\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001211 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 917\n",
      "[LightGBM] [Info] Number of data points in the train set: 113610, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 35.844494\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001207 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 918\n",
      "[LightGBM] [Info] Number of data points in the train set: 113610, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 35.321002\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006151 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 902\n",
      "[LightGBM] [Info] Number of data points in the train set: 113610, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 33.261729\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 908\n",
      "[LightGBM] [Info] Number of data points in the train set: 113610, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 33.639829\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006407 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 916\n",
      "[LightGBM] [Info] Number of data points in the train set: 113610, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 33.324038\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 924\n",
      "[LightGBM] [Info] Number of data points in the train set: 113609, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 36.368492\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001808 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 921\n",
      "[LightGBM] [Info] Number of data points in the train set: 113609, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 36.670017\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001293 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 911\n",
      "[LightGBM] [Info] Number of data points in the train set: 113609, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 35.904092\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005605 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 909\n",
      "[LightGBM] [Info] Number of data points in the train set: 113610, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 36.283813\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001681 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 856\n",
      "[LightGBM] [Info] Number of data points in the train set: 113610, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 35.306109\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 917\n",
      "[LightGBM] [Info] Number of data points in the train set: 113610, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 35.844494\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002779 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 918\n",
      "[LightGBM] [Info] Number of data points in the train set: 113610, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 35.321002\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 902\n",
      "[LightGBM] [Info] Number of data points in the train set: 113610, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 33.261729\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005234 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 908\n",
      "[LightGBM] [Info] Number of data points in the train set: 113610, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 33.639829\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005626 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 916\n",
      "[LightGBM] [Info] Number of data points in the train set: 113610, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 33.324038\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 924\n",
      "[LightGBM] [Info] Number of data points in the train set: 113609, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 36.368492\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006276 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 921\n",
      "[LightGBM] [Info] Number of data points in the train set: 113609, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 36.670017\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007576 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 911\n",
      "[LightGBM] [Info] Number of data points in the train set: 113609, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 35.904092\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002724 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 909\n",
      "[LightGBM] [Info] Number of data points in the train set: 113610, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 36.283813\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007302 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 856\n",
      "[LightGBM] [Info] Number of data points in the train set: 113610, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 35.306109\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006800 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 917\n",
      "[LightGBM] [Info] Number of data points in the train set: 113610, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 35.844494\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001631 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 918\n",
      "[LightGBM] [Info] Number of data points in the train set: 113610, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 35.321002\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006825 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 902\n",
      "[LightGBM] [Info] Number of data points in the train set: 113610, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 33.261729\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006101 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 908\n",
      "[LightGBM] [Info] Number of data points in the train set: 113610, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 33.639829\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007536 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 916\n",
      "[LightGBM] [Info] Number of data points in the train set: 113610, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 33.324038\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007707 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 924\n",
      "[LightGBM] [Info] Number of data points in the train set: 113609, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 36.368492\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007238 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 921\n",
      "[LightGBM] [Info] Number of data points in the train set: 113609, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 36.670017\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005197 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 911\n",
      "[LightGBM] [Info] Number of data points in the train set: 113609, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 35.904092\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007606 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 909\n",
      "[LightGBM] [Info] Number of data points in the train set: 113610, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 36.283813\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007196 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 856\n",
      "[LightGBM] [Info] Number of data points in the train set: 113610, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 35.306109\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 917\n",
      "[LightGBM] [Info] Number of data points in the train set: 113610, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 35.844494\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002526 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 918\n",
      "[LightGBM] [Info] Number of data points in the train set: 113610, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 35.321002\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001776 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 902\n",
      "[LightGBM] [Info] Number of data points in the train set: 113610, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 33.261729\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001662 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 908\n",
      "[LightGBM] [Info] Number of data points in the train set: 113610, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 33.639829\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001829 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 916\n",
      "[LightGBM] [Info] Number of data points in the train set: 113610, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 33.324038\n",
      "Média do R²: 0.8786\n",
      "Média do MSE: 18.5436\n",
      "Média do MAE: 2.5144\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "import numpy as np\n",
    "\n",
    "# Criar o modelo\n",
    "model = lgb.LGBMRegressor(n_estimators=100, max_depth=-1, random_state=42)\n",
    "\n",
    "# Obter previsões com validação cruzada\n",
    "y_predict = cross_val_predict(model, X, y, cv=10)\n",
    "\n",
    "# Calcular métricas\n",
    "r2_scores = cross_val_score(model, X, y, cv=10, scoring='r2')\n",
    "mse_scores = cross_val_score(model, X, y, cv=10, scoring='neg_mean_squared_error')\n",
    "mae_scores = cross_val_score(model, X, y, cv=10, scoring='neg_mean_absolute_error')\n",
    "\n",
    "# Resultados\n",
    "print(f\"Média do R²: {np.mean(r2_scores):.4f}\")\n",
    "print(f\"Média do MSE: {-np.mean(mse_scores):.4f}\")  # Inverte o sinal do MSE\n",
    "print(f\"Média do MAE: {-np.mean(mae_scores):.4f}\")  # Inverte o sinal do MAE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7efed8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012101 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 893\n",
      "[LightGBM] [Info] Number of data points in the train set: 100986, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 35.163547\n",
      "Melhores hiperparâmetros: {'subsample': 1.0, 'num_leaves': 50, 'n_estimators': 200, 'max_depth': -1, 'learning_rate': 0.2, 'colsample_bytree': 1.0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Separar 80% treino e 20% teste antes de otimizar hiperparâmetros\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definir o modelo\n",
    "model = lgb.LGBMRegressor(objective='regression')\n",
    "\n",
    "# Definir espaço de busca dos hiperparâmetros\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [-1, 5, 10, 15],\n",
    "    'num_leaves': [20, 31, 40, 50],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# RandomizedSearchCV com validação cruzada apenas no treino\n",
    "random_search = RandomizedSearchCV(\n",
    "    model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=20,\n",
    "    scoring='r2',\n",
    "    cv=10,  # Validação cruzada apenas no conjunto de treino\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Executar a busca de hiperparâmetros apenas no conjunto de treino\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Melhor combinação encontrada\n",
    "best_params = random_search.best_params_\n",
    "print(\"Melhores hiperparâmetros:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f4c45e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004309 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 893\n",
      "[LightGBM] [Info] Number of data points in the train set: 100986, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 35.163547\n",
      "\n",
      "=== Workload 1.0 ===\n",
      "MAE: 1.6985\n",
      "RMSE: 2.6962\n",
      "R²: 0.9798\n",
      "Tempo médio de inferência: 164.35 ms\n",
      "Uso médio de memória: 129.21 MB\n",
      "Número de inferências em 300 segundos: 1825\n",
      "\n",
      "=== Workload 0.5 ===\n",
      "MAE: 1.7037\n",
      "RMSE: 2.5752\n",
      "R²: 0.9808\n",
      "Tempo médio de inferência: 81.09 ms\n",
      "Uso médio de memória: 137.83 MB\n",
      "Número de inferências em 300 segundos: 3696\n",
      "\n",
      "=== Workload 0.1 ===\n",
      "MAE: 1.7251\n",
      "RMSE: 2.6001\n",
      "R²: 0.9805\n",
      "Tempo médio de inferência: 17.86 ms\n",
      "Uso médio de memória: 153.61 MB\n",
      "Número de inferências em 300 segundos: 16703\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import psutil\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, root_mean_squared_error\n",
    "\n",
    "def benchmark_inference(model, X_test, y_test, workload, duration_seconds=300):\n",
    "    n_samples = int(len(X_test) * workload)\n",
    "    X_benchmark = X_test[:n_samples]\n",
    "    y_benchmark = y_test[:n_samples]\n",
    "\n",
    "    start_time = time.time()\n",
    "    inference_times = []\n",
    "    predictions = []\n",
    "    memory_usages = []\n",
    "\n",
    "    while time.time() - start_time < duration_seconds:\n",
    "        t0 = time.perf_counter()\n",
    "        y_pred = model.predict(X_benchmark)\n",
    "        t1 = time.perf_counter()\n",
    "\n",
    "        inference_times.append(t1 - t0)\n",
    "        predictions.append(y_pred)\n",
    "        memory_usages.append(psutil.Process().memory_info().rss / 1024**2)  # Em MB\n",
    "\n",
    "    y_pred_final = predictions[-1]\n",
    "    mae = mean_absolute_error(y_benchmark, y_pred_final)\n",
    "    rmse = root_mean_squared_error(y_benchmark, y_pred_final)\n",
    "    r2 = r2_score(y_benchmark, y_pred_final)\n",
    "\n",
    "    avg_time = np.mean(inference_times)\n",
    "    avg_memory = np.mean(memory_usages)\n",
    "    num_inferences = len(inference_times)\n",
    "\n",
    "    print(f\"\\n=== Workload {workload} ===\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"R²: {r2:.4f}\")\n",
    "    print(f\"Tempo médio de inferência: {avg_time*1000:.2f} ms\")\n",
    "    print(f\"Uso médio de memória: {avg_memory:.2f} MB\")\n",
    "    print(f\"Número de inferências em {duration_seconds} segundos: {num_inferences}\")\n",
    "\n",
    "# Cria o modelo com os melhores hiperparâmetros\n",
    "best_model = lgb.LGBMRegressor(\n",
    "    subsample=1.0,\n",
    "    num_leaves=50,\n",
    "    n_estimators=200,\n",
    "    max_depth=-1,\n",
    "    learning_rate=0.2,\n",
    "    colsample_bytree=1.0\n",
    ")\n",
    "\n",
    "# Treina no conjunto de treino\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Executa o benchmark para cada workload (uma vez cada)\n",
    "for workload in [1.0, 0.5, 0.1]:\n",
    "    benchmark_inference(best_model, X_test, y_test, workload, duration_seconds=300)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
